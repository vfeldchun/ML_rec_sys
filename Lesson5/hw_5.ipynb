{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1XjeTzsz7_x"
   },
   "source": [
    "## Теоретическая часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FISrRJh6z7_4"
   },
   "source": [
    "\n",
    "1. Ответьте на вопросы:  \n",
    "В чем принципиальное отличие гибридных рекомендательных систем от коллаборативной филтьтрации?  \n",
    "Приведите 2-3 примера задач, в которых необходимо использовать гибридные системы  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ответ:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коллаборативная филтьтрация основана на историии взаимодействия пользователей и итемов что плохо работает для новых пользователей или товаров, тогда как гибридные рекомендательные системы могут использовать любые сочетания алгоритмов и их результатов для формирования рекомендаций, все зависит только от фантазии разработчиков и целесообразности времени потраченого на разработку и ее сложености и как результат стоимости."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E64QMf0Oz7_6"
   },
   "source": [
    "2.  Прочитайте статью про поиск на hh.ru https://habr.com/ru/company/hh/blog/347276/\n",
    "Нам интересна именно рекомендательная система, раздел \"Производительность системы\" можно пропустить\n",
    "Какие основные отличия предложенной системы от тех подходов, которые мы разбирали на семинарах? Какие проблемы могут возникнуть при выводе такой модели в продакшен?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ответ:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные отличия что в используемом в данной сатье подходе решили от казаться от рекоменндаций на очнове резюме пользователей и просто предлогают наиболее популярные или с наибольшей вероятностью отклика вакансии разбитые по категориям платных и бесплатных вакансий. Для пользователей которые долго не обновляли резюме данный механихм не применяют а предоставляют рекомендации исходя из резюме.\n",
    "В целом исходя из такого подхода конечно повышаеться взаимодействия пользователей с вакансиями так как просто из любопвтства например пользователь может открыть вакансию из премиального сегмента что бы посмотреть за что такие деньги платят но это совершенно не гарантирует что для данного пользователя эта вакансия релевантна. Но метрики будут улучшаться. На мой взгляд основная проблема в том что в рекомендациях может быть множество не релевантных вакансий что при приведенном в статье методов их предоставления может затруднять поиск релевантных вакансий.\n",
    "Так же в предложеном подходн не учтены все группы пользователей и их инетересы а толькопользователи которые максимально пассивны.\n",
    "\n",
    "В продуктивной среде может возникнуть рост количества не релевантных вакнсий для пользователей при в целом хороших метриках, так как ориентир сделан в основном только на одну группу пользователей и не учитываеться например история взаимодействия пользователя с вакансиями, например отброшенные пользователем вакансии могут снова и снова попадать в рекомендации что есть не хорошо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tNE5pEkJz7_6"
   },
   "source": [
    "3. На вебинаре мы рассматривали модель LightFM (https://making.lyst.com/lightfm/docs/lightfm.html). В работе Data Scientist'а важную часть занимает research - исследование существующих архитектур и разбор научных статей, в которых они описываются. Вам предлагается изчуть оригинальную статью про LightFM https://arxiv.org/pdf/1507.08439.pdf и ответить на следующие вопросы:  \n",
    "1) Какой датасет используют авторы?  \n",
    "2) Что используют в качестве признаков?  \n",
    "3) С какими моделями сравнивают LightFM? Опишите их основные идеи кратко  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ответ:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Авторы работают в онлайн торговле товарами индустрии моды. Но для тестирования они выбрали два датасета:  \n",
    "    1.1 Датасет плотных данныъ MovieLens. Данный датасет оптимален для мептодов матричной факторизации. Данный датасет содержит порядка 10 милионов рейтингов фильмов оставленых примерно 72 тысячами пользователями. Вспе фильмы описываються их жанрами и списком тегов из Tag Genome.  \n",
    "    1.2. Датасет разряженных данных CrossValidated. Данный датасет оптимален для использования контентных методов. Датасет состоит из вопросов и ответов, размещенных на CrossValidated, части более крупной сети совместных сайтов вопросов и ответов StackExchange, посвященных статистике и машинному обучению. Датасет включает в себя порядка 6000 пользователей 44000 вопросов и 188000 ответов и комментариев.  \n",
    "2. Используються следующие признаки:  \n",
    "    a) Признаки тегов  \n",
    "    b) Признаки итемов  \n",
    "    с) Признаки пользователей (только для датасета CrossValidated)  \n",
    "3. Основное сравнение идет с следующими моделями:  \n",
    " a) Матричная факторизация (MF) - Классические методы матричной факторизации основаной на взаимодействии пользователь - итем и синмоидная функция связи. Данная модель должна хорошо себя показывать на плотном датасете.  \n",
    " б) Контентная (LSI-LR) - Модель основанная на чистой факторизации контентной матрицы что бы получить максимальный эффект использования колаборативной информации при конструировании взаимодействий между признаками.  \n",
    " в) Гибридная (LSI-UP) - Модель представляет профили пользователей как линейную комбинацию векторов контента итемов, затем добавляет LSI к результирующей матрице для получения латентного представления пользователй и итемов. Сначала создаеться матрица пользователь-признак, в которой каждая строка это пользователь а каждый столбец это итем полученый сумированием векторов контентных признаков. Данная матрица отображает позитивное взаимодействие пользователя и итема. Затем выполняеться нормализация матрицы с помощью SVD для получения латентных векторов пользователей и признаков.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n19OhGm_z7_7"
   },
   "source": [
    "## Практическая часть\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9a2DNsNKz7_8",
    "outputId": "8e2537c9-16c8-4ebc-b321-f4bfa253b079"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vladimirfeldcun/opt/anaconda3/lib/python3.8/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import lightfm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZnN3kRlz7__"
   },
   "source": [
    "### 1. Модуль SRC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKLq6JBxz8AA"
   },
   "source": [
    "На вебинаре было рассказано про модуль src. Он приложен в материалах. Скачайте его, изучите структуру, импортируйте функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "nHTovEfPz7_-"
   },
   "outputs": [],
   "source": [
    "# import data\n",
    "# utils functions like in webinar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Для работы с матрицами\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "\n",
    "# Матричная факторизация\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.nearest_neighbours import bm25_weight, tfidf_weight\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k\n",
    "\n",
    "# Функции из 1-ого вебинара\n",
    "import os, sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "# from src.metrics import precision_at_k, recall_at_k\n",
    "from src.utils import prefilter_items\n",
    "#from src.metrics import precision_at_k, recall_at_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5PtkoIlz8AB"
   },
   "source": [
    "### 2. Работа с признаками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U29uOLDNz8AC"
   },
   "source": [
    "У нас есть внешние данные. Что с ними не так? Чего не хватает?  \n",
    "\n",
    "Проведите исследование внешних данных и составьте какие-нибудь содержательные выводы.  \n",
    "Формально Вам нужно построить 3+ графиков (scatter plot, hist или что-то иное) и описать, что мы видим (например, товары такой-то категории болле часто покупаются в следующие дни недели или пользователи с большим достатком предпочитают такие-то товары).  \n",
    "Исследуйте те закономерности, которые Вам интересно, чем менее тривиальный вывод получается, тем лучше! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>basket_id</th>\n",
       "      <th>day</th>\n",
       "      <th>item_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>sales_value</th>\n",
       "      <th>store_id</th>\n",
       "      <th>retail_disc</th>\n",
       "      <th>trans_time</th>\n",
       "      <th>week_no</th>\n",
       "      <th>coupon_disc</th>\n",
       "      <th>coupon_match_disc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1004906</td>\n",
       "      <td>1</td>\n",
       "      <td>1.39</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1033142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    basket_id  day  item_id  quantity  sales_value  store_id  \\\n",
       "0     2375  26984851472    1  1004906         1         1.39       364   \n",
       "1     2375  26984851472    1  1033142         1         0.82       364   \n",
       "\n",
       "   retail_disc  trans_time  week_no  coupon_disc  coupon_match_disc  \n",
       "0         -0.6        1631        1          0.0                0.0  \n",
       "1          0.0        1631        1          0.0                0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('transaction_data.csv')\n",
    "\n",
    "data.columns = [col.lower() for col in data.columns]\n",
    "data.rename(columns={'household_key': 'user_id',\n",
    "                    'product_id': 'item_id'},\n",
    "           inplace=True)\n",
    "\n",
    "item_features = pd.read_csv('product.csv')\n",
    "user_features = pd.read_csv('hh_demographic.csv')\n",
    "\n",
    "# column processing\n",
    "item_features.columns = [col.lower() for col in item_features.columns]\n",
    "user_features.columns = [col.lower() for col in user_features.columns]\n",
    "\n",
    "item_features.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "user_features.rename(columns={'household_key': 'user_id'}, inplace=True)\n",
    "\n",
    "# train test split\n",
    "test_size_weeks = 3\n",
    "\n",
    "data_train = data[data['week_no'] < data['week_no'].max() - test_size_weeks]\n",
    "data_test = data[data['week_no'] >= data['week_no'].max() - test_size_weeks]\n",
    "\n",
    "data_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decreased # items from 90386 to 5001\n"
     ]
    }
   ],
   "source": [
    "n_items_before = data_train['item_id'].nunique()\n",
    "\n",
    "data_train = prefilter_items(data_train, item_features)\n",
    "\n",
    "n_items_after = data_train['item_id'].nunique()\n",
    "print('Decreased # items from {} to {}'.format(n_items_before, n_items_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>818981</th>\n",
       "      <th>819255</th>\n",
       "      <th>819308</th>\n",
       "      <th>819330</th>\n",
       "      <th>819400</th>\n",
       "      <th>819487</th>\n",
       "      <th>819590</th>\n",
       "      <th>819594</th>\n",
       "      <th>819840</th>\n",
       "      <th>819845</th>\n",
       "      <th>...</th>\n",
       "      <th>15972790</th>\n",
       "      <th>16053142</th>\n",
       "      <th>16100266</th>\n",
       "      <th>16729296</th>\n",
       "      <th>16729299</th>\n",
       "      <th>16729415</th>\n",
       "      <th>16770156</th>\n",
       "      <th>16809649</th>\n",
       "      <th>17104444</th>\n",
       "      <th>17105058</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 5001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item_id  818981    819255    819308    819330    819400    819487    819590    \\\n",
       "user_id                                                                         \n",
       "1             0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2             0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "item_id  819594    819840    819845    ...  15972790  16053142  16100266  \\\n",
       "user_id                                ...                                 \n",
       "1             0.0       0.0       0.0  ...       0.0       0.0       0.0   \n",
       "2             0.0       0.0       0.0  ...       0.0       0.0       0.0   \n",
       "\n",
       "item_id  16729296  16729299  16729415  16770156  16809649  17104444  17105058  \n",
       "user_id                                                                        \n",
       "1             0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "2             0.0       0.0       0.0       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[2 rows x 5001 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Заведем фиктивный item_id (если юзер покупал товары из топ-5000, то он \"купил\" такой товар)\n",
    "# data_train.loc[~data_train['item_id'].isin(top_5000), 'item_id'] = 999999\n",
    "\n",
    "user_item_matrix = pd.pivot_table(data_train, \n",
    "                                  index='user_id', columns='item_id', \n",
    "                                  values='quantity', # Можно пробоват ьдругие варианты\n",
    "                                  aggfunc='count', \n",
    "                                  fill_value=0\n",
    "                                 )\n",
    "\n",
    "user_item_matrix = user_item_matrix.astype(float) # необходимый тип матрицы для implicit\n",
    "\n",
    "# переведем в формат saprse matrix\n",
    "sparse_user_item = csr_matrix(user_item_matrix).tocsr()\n",
    "\n",
    "user_item_matrix.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test[data_test['item_id'].isin(data_train['item_id'].unique())]\n",
    "test_user_item_matrix = pd.pivot_table(data_test, \n",
    "                                  index='user_id', columns='item_id', \n",
    "                                  values='quantity', # Можно пробоват ьдругие варианты\n",
    "                                  aggfunc='count', \n",
    "                                  fill_value=0\n",
    "                                 )\n",
    "\n",
    "test_user_item_matrix = user_item_matrix.astype(float) # необходимый тип матрицы для implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "userids = user_item_matrix.index.values\n",
    "itemids = user_item_matrix.columns.values\n",
    "\n",
    "matrix_userids = np.arange(len(userids))\n",
    "matrix_itemids = np.arange(len(itemids))\n",
    "\n",
    "id_to_itemid = dict(zip(matrix_itemids, itemids))\n",
    "id_to_userid = dict(zip(matrix_userids, userids))\n",
    "\n",
    "itemid_to_id = dict(zip(itemids, matrix_itemids))\n",
    "userid_to_id = dict(zip(userids, matrix_userids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_desc</th>\n",
       "      <th>marital_status_code</th>\n",
       "      <th>income_desc</th>\n",
       "      <th>homeowner_desc</th>\n",
       "      <th>hh_comp_desc</th>\n",
       "      <th>household_size_desc</th>\n",
       "      <th>kid_category_desc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65+</td>\n",
       "      <td>A</td>\n",
       "      <td>35-49K</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>2 Adults No Kids</td>\n",
       "      <td>2</td>\n",
       "      <td>None/Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age_desc marital_status_code income_desc homeowner_desc  \\\n",
       "user_id                                                           \n",
       "1            65+                   A      35-49K      Homeowner   \n",
       "2            NaN                 NaN         NaN            NaN   \n",
       "\n",
       "             hh_comp_desc household_size_desc kid_category_desc  \n",
       "user_id                                                          \n",
       "1        2 Adults No Kids                   2      None/Unknown  \n",
       "2                     NaN                 NaN               NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_feat = pd.DataFrame(user_item_matrix.index)\n",
    "user_feat = user_feat.merge(user_features, on='user_id', how='left')\n",
    "user_feat.set_index('user_id', inplace=True)\n",
    "\n",
    "item_feat = pd.DataFrame(user_item_matrix.columns)\n",
    "item_feat = item_feat.merge(item_features, on='item_id', how='left')\n",
    "item_feat.set_index('item_id', inplace=True)\n",
    "\n",
    "user_feat.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_desc</th>\n",
       "      <th>marital_status_code</th>\n",
       "      <th>income_desc</th>\n",
       "      <th>homeowner_desc</th>\n",
       "      <th>hh_comp_desc</th>\n",
       "      <th>household_size_desc</th>\n",
       "      <th>kid_category_desc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65+</td>\n",
       "      <td>A</td>\n",
       "      <td>35-49K</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>2 Adults No Kids</td>\n",
       "      <td>2</td>\n",
       "      <td>None/Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age_desc marital_status_code income_desc homeowner_desc  \\\n",
       "user_id                                                           \n",
       "1            65+                   A      35-49K      Homeowner   \n",
       "2            NaN                 NaN         NaN            NaN   \n",
       "\n",
       "             hh_comp_desc household_size_desc kid_category_desc  \n",
       "user_id                                                          \n",
       "1        2 Adults No Kids                   2      None/Unknown  \n",
       "2                     NaN                 NaN               NaN  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_feat_test = pd.DataFrame(test_user_item_matrix.index)\n",
    "user_feat_test = user_feat_test.merge(user_features, on='user_id', how='left')\n",
    "user_feat_test.set_index('user_id', inplace=True)\n",
    "\n",
    "item_feat_test = pd.DataFrame(test_user_item_matrix.columns)\n",
    "item_feat_test = item_feat_test.merge(item_features, on='item_id', how='left')\n",
    "item_feat_test.set_index('item_id', inplace=True)\n",
    "\n",
    "user_feat_test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feat_lightfm = pd.get_dummies(user_feat, columns=user_feat.columns.tolist())\n",
    "item_feat_lightfm = pd.get_dummies(item_feat, columns=item_feat.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feat_test_lightfm = pd.get_dummies(user_feat_test, columns=user_feat_test.columns.tolist())\n",
    "item_feat_test_lightfm = pd.get_dummies(item_feat_test, columns=item_feat_test.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HYWWYQmz8AC"
   },
   "source": [
    "### 3. LightFM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFZVbwN-z8AD"
   },
   "source": [
    "У этого алогритма есть множество параметров (item/user_alpha, loss, no_components).  \n",
    "Проведите эксперименты аналогично дз 3 (подберите гипперпараметры каким удобно способои и постройте графики)  \n",
    "На выходе необходимо получить pr@5 на валидации (последние 3 недели) > 2%  \n",
    "\n",
    "У Вас, скорее всего, возникнет проблема со временем обучения. Почему они возникает?    \n",
    "\n",
    "Попробуйте запустить алгоритм вообще без фичей или используйте только признаки с небольшим числом уникальных категорий. (item_features['commodity_desc'].unique() - 300 уникальных категорий - это очень много)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7fec08427ee0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LightFM(no_components=30,\n",
    "                loss='bpr', # 'warp'\n",
    "                learning_rate=0.05, \n",
    "                item_alpha=0.01, user_alpha=0.01, \n",
    "                random_state=42)\n",
    "\n",
    "model.fit((sparse_user_item > 0) * 1,  # user-item matrix из 0 и 1\n",
    "          sample_weight=coo_matrix(user_item_matrix),\n",
    "          user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "          item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "          epochs=15, \n",
    "          num_threads=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3407497"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_precision = precision_at_k(model, sparse_user_item, \n",
    "                                 user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "                                 item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "                                 k=5).mean()\n",
    "\n",
    "train_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3407497"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_precision = precision_at_k(model, csr_matrix(test_user_item_matrix).tocsr(), \n",
    "                                 user_features=csr_matrix(user_feat_test_lightfm.values).tocsr(),\n",
    "                                 item_features=csr_matrix(item_feat_test_lightfm.values).tocsr(),\n",
    "                                 k=5).mean()\n",
    "\n",
    "test_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные гиперпараметры влияющие на улучшение метрики являються item_alpha, user_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLnjWB6Lz8AD"
   },
   "source": [
    "### *Отбор признаков* * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p3-DjadOz8AE"
   },
   "source": [
    "Все данные категориальные, при ohe кодировании для товаров признаков становится невероятно много.      \n",
    "Какие стратегии отбора признаков в классическом ML Вы знаете? Применимы ли они тут?  \n",
    "\n",
    "Попробйте какие-нибудь стратегии. Удалось ли улучшить качество?\n",
    "\n",
    " \\* *задание необязательно*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gry2IYHKz8AE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m8JdZSBnz8AF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8kSXv81cz8AF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
